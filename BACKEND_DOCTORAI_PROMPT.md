# ü©∫ BACKEND AI PROMPT - DOCTOR AI FEATURE

## üéØ M·ª§C TI√äU
X√¢y d·ª±ng backend API cho feature **DoctorAI** - t∆∞ v·∫•n th√∫ y t·ª± ƒë·ªông b·∫±ng AI (Google Gemini). Frontend ƒë√£ ho√†n thi·ªán v√† c·∫ßn backend mapping ch√≠nh x√°c.

---

## üìã T·ªîNG QUAN NGHI·ªÜP V·ª§

### User Flow:
1. User upload **t·ªëi ƒëa 5 ·∫£nh** (JPG/PNG/PDF, ‚â§10MB m·ªói file)
2. User nh·∫≠p **m√¥ t·∫£ ca b·ªánh** (gi·ªëng/tu·ªïi/c√¢n n·∫∑ng/tri·ªáu ch·ª©ng)
3. User nh·∫≠p **c√¢u h·ªèi** c·ª• th·ªÉ cho AI b√°c sƒ©
4. Backend:
   - Upload ·∫£nh l√™n cloud/local storage
   - G·ª≠i ·∫£nh + m√¥ t·∫£ + c√¢u h·ªèi t·ªõi Gemini AI
   - Gemini ph√¢n t√≠ch v√† tr·∫£ l·ªùi
   - L∆∞u conversation history
5. Frontend hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi c·ªßa AI

### ƒê·∫∑c ƒëi·ªÉm:
- ‚úÖ **Conversation-based**: M·ªói cu·ªôc tr√≤ chuy·ªán c√≥ `conversationId` ƒë·ªÉ maintain context
- ‚úÖ **Image Analysis**: Gemini Vision API ƒë·ªÉ ph√¢n t√≠ch ·∫£nh th√∫ c∆∞ng
- ‚úÖ **Persistent History**: L∆∞u l·ªãch s·ª≠ chat ƒë·ªÉ user c√≥ th·ªÉ ti·∫øp t·ª•c
- ‚úÖ **Authentication Required**: Ch·ªâ user ƒë√£ login m·ªõi s·ª≠ d·ª•ng

---

## üõ£Ô∏è API ENDPOINTS C·∫¶N X√ÇY D·ª∞NG

### 1. **Upload Images API**
```http
POST /api/upload
Authorization: Bearer <token>
Content-Type: multipart/form-data
```

**Request Body:**
```javascript
FormData {
  images: File[]  // Key l√† 'images', c√≥ th·ªÉ upload nhi·ªÅu files
}
```

**Response (Success - 200):**
```json
{
  "urls": [
    "https://storage.example.com/uploads/abc123.jpg",
    "https://storage.example.com/uploads/def456.jpg",
    "https://storage.example.com/uploads/ghi789.jpg"
  ]
}
```

**Response (Error - 400):**
```json
{
  "error": "File size exceeds 10MB limit",
  "message": "K√≠ch th∆∞·ªõc file v∆∞·ª£t qu√° 10MB"
}
```

**Response (Error - 401):**
```json
{
  "error": "Unauthorized",
  "message": "B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng d·ªãch v·ª• n√†y"
}
```

**Response (Error - 413):**
```json
{
  "error": "Payload too large",
  "message": "Ch·ªâ ƒë∆∞·ª£c upload t·ªëi ƒëa 5 ·∫£nh"
}
```

---

### 2. **Chat with AI Doctor API**
```http
POST /api/chat
Authorization: Bearer <token>
Content-Type: application/json
```

**Request Body:**
```typescript
{
  conversationId?: string | null,  // null = t·∫°o conversation m·ªõi
  userText: string,                // Tin nh·∫Øn ƒë√£ ƒë∆∞·ª£c format s·∫µn
  imageUrls: string[],            // URLs t·ª´ upload endpoint
  createIfMissing?: boolean       // true = t·ª± ƒë·ªông t·∫°o conversation m·ªõi
}
```

**V√≠ d·ª• Request:**
```json
{
  "conversationId": null,
  "userText": "[M√î T·∫¢ CA B·ªÜNH]\nCh√≥ Alaska, 3 tu·ªïi, 35kg. B·ªã n√¥n m·ª≠a t·ª´ s√°ng nay, ƒÉn x∆∞∆°ng g√† t·ªëi qua.\n\n[C√ÇU H·ªéI]\nCho b√© c√≥ nguy hi·ªÉm kh√¥ng? C·∫ßn ƒëi kh√°m ngay kh√¥ng?",
  "imageUrls": [
    "https://storage.example.com/uploads/abc123.jpg",
    "https://storage.example.com/uploads/def456.jpg"
  ],
  "createIfMissing": true
}
```

**Response (Success - 200):**
```json
{
  "conversationId": "conv_1234567890",
  "reply": "D·ª±a tr√™n m√¥ t·∫£ v√† h√¨nh ·∫£nh b·∫°n cung c·∫•p, t√¨nh tr·∫°ng c·ªßa b√© c√≥ th·ªÉ do:\n\n1. **Vi√™m d·∫° d√†y ru·ªôt c·∫•p**: Do x∆∞∆°ng g√† c√≥ th·ªÉ g√¢y t·ªïn th∆∞∆°ng ni√™m m·∫°c d·∫° d√†y\n2. **T·∫Øc ngh·∫Ωn ƒë∆∞·ªùng ti√™u h√≥a**: M·∫£nh x∆∞∆°ng s·∫Øc nh·ªçn c√≥ th·ªÉ g√¢y t·∫Øc\n\n‚ö†Ô∏è **KHUY·∫æN NGH·ªä KH·∫®N C·∫§P**:\n- ƒê∆∞a b√© ƒë·∫øn ph√≤ng kh√°m ngay l·∫≠p t·ª©c\n- Kh√¥ng cho ƒÉn u·ªëng g√¨ th√™m\n- Ch·ª•p X-quang ƒë·ªÉ ki·ªÉm tra t·∫Øc ngh·∫Ωn\n\nƒê√¢y l√† t√¨nh tr·∫°ng C·∫¶N CAN THI·ªÜP S·ªöM. Vui l√≤ng li√™n h·ªá b√°c sƒ© ngay."
}
```

**Response (Error - 400):**
```json
{
  "error": "Invalid request",
  "message": "Thi·∫øu th√¥ng tin userText ho·∫∑c imageUrls"
}
```

**Response (Error - 401):**
```json
{
  "error": "Unauthorized",
  "message": "B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng DoctorAI"
}
```

**Response (Error - 404):**
```json
{
  "error": "Conversation not found",
  "message": "Kh√¥ng t√¨m th·∫•y cu·ªôc tr√≤ chuy·ªán. Vui l√≤ng t·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi."
}
```

**Response (Error - 429):**
```json
{
  "error": "Rate limit exceeded",
  "message": "B·∫°n ƒë√£ g·ª≠i qu√° nhi·ªÅu tin nh·∫Øn. Vui l√≤ng th·ª≠ l·∫°i sau 5 ph√∫t."
}
```

**Response (Error - 500):**
```json
{
  "error": "AI service error",
  "message": "C√≥ l·ªói x·∫£y ra khi k·∫øt n·ªëi v·ªõi d·ªãch v·ª• AI. Vui l√≤ng th·ª≠ l·∫°i sau."
}
```

---

## üìä DATABASE SCHEMA

### 1. **Conversations Collection/Table**
```javascript
{
  _id: ObjectId,                    // MongoDB ID
  conversationId: String,           // UUID ho·∫∑c unique string
  userId: ObjectId,                 // Reference to User
  petInfo: {                        // Optional: th√¥ng tin th√∫ c∆∞ng
    species: String,                // "dog", "cat", "bird", etc.
    breed: String,                  // "Alaska", "Golden Retriever", etc.
    age: Number,
    weight: Number
  },
  createdAt: Date,
  updatedAt: Date,
  lastActivityAt: Date,
  status: String                    // "active", "closed"
}
```

### 2. **Messages Collection/Table**
```javascript
{
  _id: ObjectId,
  conversationId: String,           // Foreign key to Conversations
  userId: ObjectId,                 // Reference to User
  role: String,                     // "user" | "assistant"
  content: {
    text: String,                   // N·ªôi dung tin nh·∫Øn
    imageUrls: [String],           // URLs c·ªßa ·∫£nh (n·∫øu c√≥)
    metadata: {                     // Metadata cho ph√¢n t√≠ch
      petSpecies: String,
      symptoms: [String],
      urgencyLevel: String         // "low", "medium", "high", "emergency"
    }
  },
  timestamp: Date,
  aiModel: String,                  // "gemini-1.5-pro" ho·∫∑c version AI
  tokensUsed: Number,              // Tracking cost
  processingTime: Number           // Milliseconds
}
```

---

## ü§ñ GOOGLE GEMINI INTEGRATION

### Setup Gemini API:
```javascript
const { GoogleGenerativeAI } = require('@google/generative-ai');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ 
  model: "gemini-1.5-pro",  // ho·∫∑c gemini-1.5-flash cho nhanh h∆°n
  generationConfig: {
    temperature: 0.7,
    topP: 0.9,
    topK: 40,
    maxOutputTokens: 2048,
  }
});
```

### System Prompt cho DoctorAI:
```javascript
const SYSTEM_PROMPT = `B·∫°n l√† m·ªôt B√ÅC Sƒ® TH√ö Y AI chuy√™n nghi·ªáp t·∫°i ph√≤ng kh√°m MyPet Clinic.

üéØ VAI TR√í C·ª¶A B·∫†N:
- Ph√¢n t√≠ch tri·ªáu ch·ª©ng v√† h√¨nh ·∫£nh th√∫ c∆∞ng
- ƒê∆∞a ra t∆∞ v·∫•n chuy√™n m√¥n d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
- ƒê√°nh gi√° m·ª©c ƒë·ªô kh·∫©n c·∫•p: LOW (theo d√µi), MEDIUM (kh√°m trong 1-2 ng√†y), HIGH (kh√°m trong ng√†y), EMERGENCY (kh√°m ngay l·∫≠p t·ª©c)
- Lu√¥n khuy·∫øn kh√≠ch ch·ªß nh√¢n ƒë·∫øn ph√≤ng kh√°m n·∫øu c√≥ d·∫•u hi·ªáu nghi√™m tr·ªçng

‚ö†Ô∏è NGUY√äN T·∫ÆC QUAN TR·ªåNG:
1. Kh√¥ng thay th·∫ø cho kh√°m tr·ª±c ti·∫øp - ch·ªâ t∆∞ v·∫•n s∆° b·ªô
2. N·∫øu t√¨nh tr·∫°ng nghi√™m tr·ªçng, PH·∫¢I khuy·∫øn ngh·ªã ƒëi kh√°m ngay
3. Kh√¥ng k√™ ƒë∆°n thu·ªëc c·ª• th·ªÉ - ch·ªâ t∆∞ v·∫•n h∆∞·ªõng x·ª≠ l√Ω
4. Lu√¥n th√¢n thi·ªán, d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p
5. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, khuy√™n ch·ªß nh√¢n ƒë·∫øn g·∫∑p b√°c sƒ©

üìã ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
- Ph√¢n t√≠ch t√¨nh tr·∫°ng
- Nguy√™n nh√¢n c√≥ th·ªÉ
- M·ª©c ƒë·ªô kh·∫©n c·∫•p
- Khuy·∫øn ngh·ªã x·ª≠ l√Ω
- L∆∞u √Ω ƒë·∫∑c bi·ªát (n·∫øu c√≥)

üêæ LO·∫†I TH√ö C∆ØNG PH·ª§C V·ª§:
Ch√≥, m√®o, chim, th·ªè, hamster, b√≤ s√°t v√† c√°c ƒë·ªông v·∫≠t c·∫£nh ph·ªï bi·∫øn.`;
```

### Chat Function v·ªõi Gemini:
```javascript
async function chatWithGemini({ userText, imageUrls, conversationHistory }) {
  try {
    // Prepare conversation context
    const history = conversationHistory.map(msg => ({
      role: msg.role === 'user' ? 'user' : 'model',
      parts: [{ text: msg.content.text }]
    }));

    // Prepare current message parts
    const parts = [{ text: SYSTEM_PROMPT + "\n\n" + userText }];
    
    // Add images if provided
    if (imageUrls && imageUrls.length > 0) {
      for (const imageUrl of imageUrls) {
        // Download image and convert to base64
        const imageData = await downloadImageAsBase64(imageUrl);
        parts.push({
          inlineData: {
            mimeType: getMimeType(imageUrl),
            data: imageData
          }
        });
      }
    }

    // Start chat session with history
    const chat = model.startChat({
      history: history,
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2048,
      }
    });

    // Send message
    const result = await chat.sendMessage(parts);
    const response = await result.response;
    const reply = response.text();

    return {
      reply,
      tokensUsed: response.usageMetadata?.totalTokenCount || 0,
      model: "gemini-1.5-pro"
    };

  } catch (error) {
    console.error('[Gemini AI Error]:', error);
    throw new Error('Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi d·ªãch v·ª• AI. Vui l√≤ng th·ª≠ l·∫°i sau.');
  }
}
```

---

## üîê AUTHENTICATION & AUTHORIZATION

### Middleware:
```javascript
const authenticateUser = async (req, res, next) => {
  try {
    const token = req.headers.authorization?.split(' ')[1];
    
    if (!token) {
      return res.status(401).json({
        error: 'Unauthorized',
        message: 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng d·ªãch v·ª• n√†y'
      });
    }

    // Verify JWT token
    const decoded = jwt.verify(token, process.env.JWT_SECRET);
    req.userId = decoded.userId;
    req.user = await User.findById(decoded.userId);
    
    if (!req.user) {
      return res.status(401).json({
        error: 'User not found',
        message: 'T√†i kho·∫£n kh√¥ng t·ªìn t·∫°i'
      });
    }

    next();
  } catch (error) {
    return res.status(401).json({
      error: 'Invalid token',
      message: 'Token kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n'
    });
  }
};
```

---

## üìÅ FILE UPLOAD HANDLING

### Multer Configuration:
```javascript
const multer = require('multer');
const path = require('path');

// Configure storage
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, 'uploads/doctor-ai/');
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    cb(null, 'pet-' + uniqueSuffix + path.extname(file.originalname));
  }
});

// File filter
const fileFilter = (req, file, cb) => {
  const allowedTypes = ['image/jpeg', 'image/png', 'image/webp', 'application/pdf'];
  
  if (allowedTypes.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new Error('Ch·ªâ ch·∫•p nh·∫≠n file JPG, PNG, WEBP ho·∫∑c PDF'));
  }
};

// Upload middleware
const upload = multer({
  storage: storage,
  fileFilter: fileFilter,
  limits: {
    fileSize: 10 * 1024 * 1024,  // 10MB
    files: 5                      // T·ªëi ƒëa 5 files
  }
});

module.exports = upload;
```

### Upload Endpoint:
```javascript
router.post('/api/upload', authenticateUser, upload.array('images', 5), async (req, res) => {
  try {
    if (!req.files || req.files.length === 0) {
      return res.status(400).json({
        error: 'No files uploaded',
        message: 'Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt ·∫£nh'
      });
    }

    // Generate URLs for uploaded files
    const urls = req.files.map(file => {
      // Option 1: Local URL
      return `${req.protocol}://${req.get('host')}/uploads/doctor-ai/${file.filename}`;
      
      // Option 2: Cloud Storage URL (n·∫øu d√πng AWS S3, Cloudinary, etc.)
      // return uploadToCloudStorage(file);
    });

    res.json({ urls });

  } catch (error) {
    console.error('[Upload Error]:', error);
    res.status(500).json({
      error: 'Upload failed',
      message: error.message || 'Kh√¥ng th·ªÉ t·∫£i ·∫£nh l√™n. Vui l√≤ng th·ª≠ l·∫°i.'
    });
  }
});
```

---

## üõ°Ô∏è RATE LIMITING

```javascript
const rateLimit = require('express-rate-limit');

// Rate limiter for chat endpoint
const chatLimiter = rateLimit({
  windowMs: 5 * 60 * 1000, // 5 minutes
  max: 10, // Max 10 requests per 5 minutes
  message: {
    error: 'Rate limit exceeded',
    message: 'B·∫°n ƒë√£ g·ª≠i qu√° nhi·ªÅu tin nh·∫Øn. Vui l√≤ng th·ª≠ l·∫°i sau 5 ph√∫t.'
  },
  standardHeaders: true,
  legacyHeaders: false,
  // S·ª≠ d·ª•ng userId ƒë·ªÉ track
  keyGenerator: (req) => req.userId || req.ip
});

// Rate limiter for upload endpoint
const uploadLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 20, // Max 20 uploads per 15 minutes
  message: {
    error: 'Upload rate limit exceeded',
    message: 'B·∫°n ƒë√£ t·∫£i qu√° nhi·ªÅu ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i sau.'
  }
});

// Apply to routes
router.post('/api/chat', authenticateUser, chatLimiter, handleChat);
router.post('/api/upload', authenticateUser, uploadLimiter, upload.array('images', 5), handleUpload);
```

---

## üîÑ CHAT ENDPOINT IMPLEMENTATION

```javascript
router.post('/api/chat', authenticateUser, chatLimiter, async (req, res) => {
  try {
    const { conversationId, userText, imageUrls, createIfMissing } = req.body;
    const userId = req.userId;

    // Validate input
    if (!userText || typeof userText !== 'string') {
      return res.status(400).json({
        error: 'Invalid input',
        message: 'Vui l√≤ng nh·∫≠p n·ªôi dung tin nh·∫Øn'
      });
    }

    let conversation;

    // Find or create conversation
    if (conversationId) {
      conversation = await Conversation.findOne({ 
        conversationId, 
        userId 
      });
      
      if (!conversation && !createIfMissing) {
        return res.status(404).json({
          error: 'Conversation not found',
          message: 'Kh√¥ng t√¨m th·∫•y cu·ªôc tr√≤ chuy·ªán'
        });
      }
    }

    if (!conversation || createIfMissing) {
      // Create new conversation
      conversation = await Conversation.create({
        conversationId: `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        userId: userId,
        createdAt: new Date(),
        lastActivityAt: new Date(),
        status: 'active'
      });
    }

    // Save user message
    const userMessage = await Message.create({
      conversationId: conversation.conversationId,
      userId: userId,
      role: 'user',
      content: {
        text: userText,
        imageUrls: imageUrls || []
      },
      timestamp: new Date()
    });

    // Get conversation history (last 10 messages for context)
    const conversationHistory = await Message.find({
      conversationId: conversation.conversationId
    })
      .sort({ timestamp: -1 })
      .limit(10)
      .lean();

    // Reverse to get chronological order
    conversationHistory.reverse();

    // Call Gemini AI
    const startTime = Date.now();
    const aiResponse = await chatWithGemini({
      userText,
      imageUrls: imageUrls || [],
      conversationHistory
    });
    const processingTime = Date.now() - startTime;

    // Save AI response
    await Message.create({
      conversationId: conversation.conversationId,
      userId: userId,
      role: 'assistant',
      content: {
        text: aiResponse.reply,
        imageUrls: []
      },
      timestamp: new Date(),
      aiModel: aiResponse.model,
      tokensUsed: aiResponse.tokensUsed,
      processingTime
    });

    // Update conversation
    await Conversation.findByIdAndUpdate(conversation._id, {
      lastActivityAt: new Date()
    });

    // Return response
    res.json({
      conversationId: conversation.conversationId,
      reply: aiResponse.reply
    });

  } catch (error) {
    console.error('[Chat Error]:', error);
    
    if (error.message.includes('AI')) {
      return res.status(500).json({
        error: 'AI service error',
        message: error.message
      });
    }
    
    res.status(500).json({
      error: 'Internal server error',
      message: 'C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i sau.'
    });
  }
});
```

---

## üìù ROUTES STRUCTURE

```javascript
// routes/doctorAI.routes.js
const express = require('express');
const router = express.Router();
const { authenticateUser } = require('../middleware/auth');
const { chatLimiter, uploadLimiter } = require('../middleware/rateLimiter');
const upload = require('../middleware/upload');
const { handleUpload, handleChat } = require('../controllers/doctorAI.controller');

// Upload images
router.post('/upload', 
  authenticateUser, 
  uploadLimiter, 
  upload.array('images', 5), 
  handleUpload
);

// Chat with AI Doctor
router.post('/chat', 
  authenticateUser, 
  chatLimiter, 
  handleChat
);

module.exports = router;
```

```javascript
// app.js ho·∫∑c server.js
const doctorAIRoutes = require('./routes/doctorAI.routes');

app.use('/api', doctorAIRoutes);

// Serve static files (uploaded images)
app.use('/uploads', express.static('uploads'));
```

---

## üß™ TESTING

### Test Upload Endpoint:
```bash
curl -X POST http://localhost:5000/api/upload \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "images=@pet1.jpg" \
  -F "images=@pet2.jpg"
```

### Test Chat Endpoint:
```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "conversationId": null,
    "userText": "[M√î T·∫¢ CA B·ªÜNH]\nCh√≥ Alaska, 3 tu·ªïi, 35kg. N√¥n m·ª≠a.\n\n[C√ÇU H·ªéI]\nC√≥ nguy hi·ªÉm kh√¥ng?",
    "imageUrls": ["http://localhost:5000/uploads/doctor-ai/pet-123.jpg"],
    "createIfMissing": true
  }'
```

---

## üîß ENVIRONMENT VARIABLES

```env
# .env file
GEMINI_API_KEY=your_gemini_api_key_here
JWT_SECRET=your_jwt_secret_here
MONGODB_URI=mongodb://localhost:27017/mypet-clinic
PORT=5000

# File upload
MAX_FILE_SIZE=10485760  # 10MB in bytes
MAX_FILES=5

# Rate limiting
CHAT_RATE_LIMIT_WINDOW=300000  # 5 minutes in ms
CHAT_RATE_LIMIT_MAX=10
UPLOAD_RATE_LIMIT_WINDOW=900000  # 15 minutes
UPLOAD_RATE_LIMIT_MAX=20

# Cloud storage (optional)
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
AWS_S3_BUCKET=mypet-doctor-ai
CLOUDINARY_URL=cloudinary://...
```

---

## ‚úÖ CHECKLIST IMPLEMENTATION

- [ ] Setup Gemini AI v·ªõi API key
- [ ] T·∫°o database schema (Conversations & Messages)
- [ ] Implement authentication middleware
- [ ] Setup multer cho file upload
- [ ] T·∫°o `/api/upload` endpoint
- [ ] T·∫°o `/api/chat` endpoint v·ªõi Gemini integration
- [ ] Implement rate limiting
- [ ] Add error handling ƒë·∫ßy ƒë·ªß
- [ ] Test v·ªõi frontend
- [ ] Deploy v√† configure cloud storage (optional)
- [ ] Monitor API usage v√† cost
- [ ] Add logging cho debugging

---

## üé® FRONTEND INTEGRATION

Frontend ƒë√£ S·∫¥N S√ÄNG v√† ch·ªâ c·∫ßn backend mapping ƒë√∫ng:

### Frontend Flow:
1. User upload files ‚Üí Call `POST /api/upload` ‚Üí Nh·∫≠n `urls[]`
2. User nh·∫≠p m√¥ t·∫£ + c√¢u h·ªèi ‚Üí Format th√†nh `userText`
3. Click "G·ª≠i" ‚Üí Call `POST /api/chat` v·ªõi:
   - `conversationId` (null l·∫ßn ƒë·∫ßu)
   - `userText` (ƒë√£ format)
   - `imageUrls` (t·ª´ step 1)
   - `createIfMissing: true`
4. Backend tr·∫£ v·ªÅ `{ conversationId, reply }`
5. Frontend hi·ªÉn th·ªã reply v√† l∆∞u `conversationId` cho l·∫ßn sau

### Data Format Example:
```javascript
// Frontend g·ª≠i ƒëi
{
  conversationId: null,  // ho·∫∑c "conv_123" n·∫øu ti·∫øp t·ª•c chat
  userText: "[M√î T·∫¢ CA B·ªÜNH]\nCh√≥ Alaska, 3 tu·ªïi, 35kg. N√¥n m·ª≠a t·ª´ s√°ng.\n\n[C√ÇU H·ªéI]\nCho b√© c√≥ nguy hi·ªÉm kh√¥ng?",
  imageUrls: [
    "http://localhost:5000/uploads/doctor-ai/pet-1732234567890.jpg"
  ],
  createIfMissing: true
}

// Backend tr·∫£ v·ªÅ
{
  conversationId: "conv_1732234567890_abc123",
  reply: "D·ª±a tr√™n m√¥ t·∫£ v√† h√¨nh ·∫£nh, t√¨nh tr·∫°ng c·ªßa b√©..."
}
```

---

## üìö REFERENCES

- [Google Gemini API Documentation](https://ai.google.dev/docs)
- [Gemini Vision API](https://ai.google.dev/tutorials/vision_quickstart)
- [Express Multer](https://github.com/expressjs/multer)
- [Express Rate Limit](https://github.com/express-rate-limit/express-rate-limit)

---

## üöÄ DEPLOY NOTES

### Backend c·∫ßn:
1. Node.js server (Express)
2. MongoDB database
3. Gemini API key (free tier c√≥ s·∫µn)
4. Storage cho uploaded files:
   - Local: D√πng `multer` + serve static
   - Cloud: AWS S3, Cloudinary, Google Cloud Storage

### Costs estimate:
- Gemini API: Free tier 15 requests/minute
- Storage: ~$0.023/GB/month (AWS S3)
- Server: T√πy provider

---

## üí° T√ìM T·∫ÆT

**Backend c·∫ßn implement 2 endpoints ch√≠nh:**

1. **`POST /api/upload`**: Upload images ‚Üí Tr·∫£ v·ªÅ URLs
2. **`POST /api/chat`**: Chat v·ªõi AI ‚Üí Tr·∫£ v·ªÅ reply + conversationId

**Tech stack g·ª£i √Ω:**
- Node.js + Express
- MongoDB (Mongoose)
- Google Gemini AI
- Multer (file upload)
- JWT authentication
- Express Rate Limit

**Frontend ƒê√É HO√ÄN TH√ÄNH v√† ch·ªâ c·∫ßn backend mapping ƒë√∫ng spec n√†y!** ‚úÖ

